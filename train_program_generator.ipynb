{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd,autograd,init\n",
    "from mxnet.gluon import Trainer,data as gdata,loss as gloss\n",
    "from d2l import mxnet as d2l\n",
    "\n",
    "from dataset import Synthesis3D\n",
    "from model import BlockOuterNet\n",
    "from criterion import LSTMClassCriterion, LSTMRegressCriterion,BatchIoU\n",
    "from misc import clip_gradient, decode_to_shape_new,gather,decode_multiple_block\n",
    "from options import options_train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, model, crit_cls, crit_reg, optimizer, opt,ctx):\n",
    "    \"\"\"\n",
    "    One epoch training\n",
    "    \"\"\"\n",
    "    cls_w = opt.cls_weight\n",
    "    reg_w = opt.reg_weight\n",
    "    # the prob: > 1\n",
    "    # the input of step t Operator where is missing FInferType attributeis always sampled from the output of step t-1\n",
    "    sample_prob = opt.inner_sample_prob\n",
    "\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        #data, pgm, pgm_mask, param, param_mask\n",
    "        shapes, labels, masks, params, param_masks = data[0], data[1], data[2], data[3], data[4]\n",
    "        gt = shapes\n",
    "        shapes = nd.expand_dims(shapes, axis = 1)\n",
    "        #print(labels[0],params[0])\n",
    "        shapes = shapes.as_in_context(ctx)\n",
    "        \n",
    "        labels = labels.as_in_context(ctx)\n",
    "        labels2 = labels.as_in_context(ctx)\n",
    "        \n",
    "        masks = masks.as_in_context(ctx)\n",
    "        params = params.as_in_context(ctx)\n",
    "        param_masks = param_masks.as_in_context(ctx)\n",
    "        \n",
    "        \n",
    "        #shapes.attach_grad(),labels.attach_grad()\n",
    "        with autograd.record():\n",
    "            out = model(shapes, labels, sample_prob)\n",
    "            #out = model.decode(shapes)\n",
    "        \n",
    "            # reshape\n",
    "            bsz, n_block, n_step = labels.shape\n",
    "            labels = labels.reshape(bsz, -1)\n",
    "            masks = masks.reshape(bsz, -1)\n",
    "            out_pgm = out[0].reshape(bsz, n_block * n_step, opt.program_size + 1)\n",
    "            \n",
    "            bsz, n_block, n_step, n_param = params.shape\n",
    "            params = params.reshape(bsz, n_block * n_step, n_param)\n",
    "            param_masks = param_masks.reshape(bsz, n_block * n_step, n_param)\n",
    "            out_param = out[1].reshape(bsz, n_block * n_step, n_param)\n",
    "            \n",
    "            loss_cls, acc = crit_cls(out_pgm, labels, masks)\n",
    "            loss_reg = crit_reg(out_param, params, param_masks)\n",
    "            loss = cls_w*loss_cls+reg_w*loss_reg\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step(bsz,ignore_stale_grad=True)\n",
    "        \n",
    "        loss_cls = loss_cls.mean().asscalar()\n",
    "        loss_reg = loss_reg.mean().asscalar()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        \n",
    "        if idx % (opt.info_interval*10) == 0:\n",
    "            out_1 = nd.round(out[0]).astype('int64')\n",
    "            out_2 =nd.round(out[1]).astype('int64')\n",
    "            pred = nd.from_numpy(decode_multiple_block(out_1, out_2)).astype(\"float32\").as_in_context(mx.cpu())\n",
    "            IoU = BatchIoU(pred,gt)\n",
    "            print(\"Train: epoch {} batch {}/{},loss_cls = {:.3f},loss_reg = {:.3f},acc = {:.3f},IoU = {:.3f},time = {:.2f}\"\n",
    "                  .format(epoch, idx, len(train_loader), loss_cls, loss_reg, acc[0].asscalar(), IoU.mean(),end - start))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "\n",
    "def validate(epoch, val_loader, model, crit_cls, crit_reg, opt,ctx, gen_shape=False):\n",
    "    \"\"\"\n",
    "    One validation\n",
    "    \"\"\"\n",
    "    generated_shapes = []\n",
    "    original_shapes = []\n",
    "    sample_prob = opt.inner_sample_prob\n",
    "    loss_cls_sum,loss_reg_sum,n = 0.0,0.0,0\n",
    "    \n",
    "    for idx, data in enumerate(val_loader):\n",
    "        start = time.time()\n",
    "\n",
    "        shapes, labels, masks, params, param_masks = data[0], data[1], data[2], data[3], data[4]\n",
    "        gt = shapes\n",
    "        shapes = nd.expand_dims(shapes, axis = 1)\n",
    "\n",
    "        shapes = shapes.as_in_context(ctx)\n",
    "        labels = labels.as_in_context(ctx)\n",
    "        masks = masks.as_in_context(ctx)\n",
    "        params = params.as_in_context(ctx)\n",
    "        param_masks = param_masks.as_in_context(ctx)\n",
    "        #with autograd.train_mode():\n",
    "        out = model.decode(shapes)\n",
    "        #out = model(shapes, labels, sample_prob)\n",
    "        bsz, n_block, n_step = labels.shape\n",
    "        labels = labels.reshape(bsz, n_block * n_step)\n",
    "        masks = masks.reshape(bsz, n_block * n_step)\n",
    "        out_pgm = out[0].reshape(bsz, n_block * n_step, opt.program_size + 1)\n",
    "\n",
    "        bsz, n_block, n_step, n_param = params.shape\n",
    "        params = params.reshape(bsz, n_block * n_step, n_param)\n",
    "        param_masks = param_masks.reshape(bsz, n_block * n_step, n_param)\n",
    "        out_param = out[1].reshape(bsz, n_block * n_step, n_param)\n",
    "        loss_cls, acc = crit_cls(out_pgm, labels, masks)\n",
    "        loss_reg = crit_reg(out_param, params, param_masks)\n",
    "   \n",
    "        end = time.time()\n",
    "        \n",
    "        \n",
    "        loss_cls = loss_cls.mean().asscalar()\n",
    "        loss_reg = loss_reg.mean().asscalar()\n",
    "        \n",
    "        \n",
    "        if idx % opt.info_interval == 0:\n",
    "            out_1 = nd.round(out[0]).astype('int64')\n",
    "            out_2 = nd.round(out[1]).astype('int64')\n",
    "            pred = nd.from_numpy(decode_multiple_block(out_1, out_2)).astype(\"float32\").as_in_context(mx.cpu())\n",
    "            IoU = BatchIoU(pred,gt)\n",
    "            print(\"Test: epoch {} batch {}/{}, loss_cls = {:.3f}, loss_reg = {:.3f}, acc = {:.3f}, IoU = {:.3f} time = {:.3f}\"\n",
    "                  .format(epoch, idx, len(val_loader), loss_cls, loss_reg, acc[0].asscalar(), IoU.mean(), end - start))\n",
    "            sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = options_train_generator.parse()\n",
    "\n",
    "print('===== arguments: program generator =====')\n",
    "for key, val in vars(opt).items():\n",
    "    print(\"{:20} {}\".format(key, val))\n",
    "print('===== arguments: program generator =====')\n",
    "\n",
    "if not os.path.isdir(opt.save_folder):\n",
    "    os.makedirs(opt.save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "ctx = d2l.try_gpu()\n",
    "model = BlockOuterNet(opt)\n",
    "model.init_blocks(ctx)\n",
    "\n",
    "crit_cls = LSTMClassCriterion()\n",
    "crit_reg = LSTMRegressCriterion()\n",
    "ctri_cls = crit_cls.initialize(ctx = ctx)\n",
    "ctri_reg = crit_reg.initialize(ctx = ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = Trainer(model.collect_params(),\"adam\",\n",
    "                    {\"learning_rate\":opt.learning_rate,\"wd\":opt.weight_decay,\n",
    "                     'beta1':opt.beta1, 'beta2':opt.beta2, 'clip_gradient': opt.grad_clip})\n",
    "train_from0 = False;\n",
    "if train_from0:\n",
    "    if os.path.exists(\"model/model of blockouternet2\"):\n",
    "        model.load_parameters('model/model of blockouternet2')\n",
    "        print(\"loaded parameter of model2\")\n",
    "    if os.path.exists('model/optimizer of PG2'):\n",
    "        optimizer.load_states('model/optimizer of PG2')\n",
    "        print(\"loaded state of trainer2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "L2_loss = gloss.L2Loss()\n",
    "#optimizer = Trainer(model.collect_params(),\"sgd\",\n",
    "#                    {\"learning_rate\":opt.learning_rate,\"wd\":opt.weight_decay,'clip_gradient': opt.grad_clip})\n",
    "\n",
    "# build dataloader\n",
    "\n",
    "train_set = Synthesis3D(opt.train_file, n_block=opt.outer_seq_length)\n",
    "train_loader = gdata.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.num_workers,\n",
    ")\n",
    "val_set = Synthesis3D(opt.val_file, n_block=opt.outer_seq_length)\n",
    "val_loader = gdata.DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.num_workers,\n",
    ")\n",
    "\n",
    "for epoch in range(1, opt.epochs+1):\n",
    "    print(\"###################\")\n",
    "    print(\"training\")\n",
    "    \n",
    "    train(epoch, train_loader, model, crit_cls, crit_reg, optimizer, opt,ctx)\n",
    "\n",
    "    print(\"###################\")\n",
    "    print(\"testing\")\n",
    "    validate(epoch, val_loader, model, crit_cls, crit_reg, opt,ctx,True)\n",
    "    if epoch % 1 == 0:\n",
    "        print('Saving...')\n",
    "        optimizer.save_states('model/optimizer of PG2'),\n",
    "        model.save_parameters(\"model/model of blockouternet2\")\n",
    "        #state = {\n",
    "        #    'opt': opt,\n",
    "        #    'epoch': epoch\n",
    "        #}\n",
    "        #save_file = os.path.join(opt.save_folder, 'ckpt_epoch_{epoch}.t7'.format(epoch=epoch))\n",
    "        #np.save(state, save_file)\n",
    "optimizer.save_states('model/optimizer of PG2'),\n",
    "model.save_parameters(\"model/model of blockouternet2\")\n",
    "#state = {\n",
    "#    'opt': opt,\n",
    "#    'epoch': opt.epochs\n",
    "#}\n",
    "#save_file = os.path.join(opt.save_folder, 'program_generator.t7')\n",
    "#nd.save(state, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def set_bn_eval(m):\n",
    "    if m.prefix[:9]=='batchnorm':\n",
    "        m._kwargs['momentum'] = 0       \n",
    "model.apply(set_bn_eval)\n",
    "'''\n",
    "for epoch in range(1, opt.epochs+1):\n",
    "    print(\"###################\")\n",
    "    print(\"testing\")\n",
    "    validate(epoch, val_loader, model, crit_cls, crit_reg, opt,ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer.set_learning_rate(opt.learning_rate*0.1)\n",
    "optimizer.save_states('model/optimizer of PG2'),\n",
    "model.save_parameters(\"model/model of blockouternet2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nd.arange(10).astype('int32')\n",
    "b = nd.random_randint(10,13,shape = a.shape)\n",
    "idx = nd.random_randint(0,2,shape = a.shape)\n",
    "print(idx,a,b)\n",
    "nd.where(idx,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd,autograd,init\n",
    "from mxnet.gluon import Trainer,data as gdata,loss as gloss\n",
    "from d2l import mxnet as d2l\n",
    "\n",
    "from dataset import Synthesis3D\n",
    "from model import BlockOuterNet\n",
    "from criterion import LSTMClassCriterion, LSTMRegressCriterion,BatchIoU\n",
    "from misc import clip_gradient, decode_to_shape_new,gather,decode_multiple_block\n",
    "from options import options_train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, model, crit_cls, crit_reg, optimizer, opt,ctx):\n",
    "    \"\"\"\n",
    "    One epoch training\n",
    "    \"\"\"\n",
    "    cls_w = opt.cls_weight\n",
    "    reg_w = opt.reg_weight\n",
    "    # the prob: > 1\n",
    "    # the input of step t Operator where is missing FInferType attributeis always sampled from the output of step t-1\n",
    "    sample_prob = opt.inner_sample_prob\n",
    "\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        #data, pgm, pgm_mask, param, param_mask\n",
    "        shapes, labels, masks, params, param_masks = data[0], data[1], data[2], data[3], data[4]\n",
    "        gt = shapes\n",
    "        shapes = nd.expand_dims(shapes, axis = 1)\n",
    "        #print(labels[0],params[0])\n",
    "        shapes = shapes.as_in_context(ctx)\n",
    "        \n",
    "        labels = labels.as_in_context(ctx)\n",
    "        labels2 = labels.as_in_context(ctx)\n",
    "        \n",
    "        masks = masks.as_in_context(ctx)\n",
    "        params = params.as_in_context(ctx)\n",
    "        param_masks = param_masks.as_in_context(ctx)\n",
    "        \n",
    "        \n",
    "        #shapes.attach_grad(),labels.attach_grad()\n",
    "        with autograd.record():\n",
    "            out = model(shapes, labels, sample_prob)\n",
    "            #out = model.decode(shapes)\n",
    "        \n",
    "            # reshape\n",
    "            bsz, n_block, n_step = labels.shape\n",
    "            labels = labels.reshape(bsz, -1)\n",
    "            masks = masks.reshape(bsz, -1)\n",
    "            out_pgm = out[0].reshape(bsz, n_block * n_step, opt.program_size + 1)\n",
    "            \n",
    "            bsz, n_block, n_step, n_param = params.shape\n",
    "            params = params.reshape(bsz, n_block * n_step, n_param)\n",
    "            param_masks = param_masks.reshape(bsz, n_block * n_step, n_param)\n",
    "            out_param = out[1].reshape(bsz, n_block * n_step, n_param)\n",
    "            \n",
    "            loss_cls, acc = crit_cls(out_pgm, labels, masks)\n",
    "            loss_reg = crit_reg(out_param, params, param_masks)\n",
    "            loss = cls_w*loss_cls+reg_w*loss_reg\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step(bsz,ignore_stale_grad=True)\n",
    "        \n",
    "        loss_cls = loss_cls.mean().asscalar()\n",
    "        loss_reg = loss_reg.mean().asscalar()\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        \n",
    "        if idx % (opt.info_interval*10) == 0:\n",
    "            out_1 = nd.round(out[0]).astype('int64')\n",
    "            out_2 =nd.round(out[1]).astype('int64')\n",
    "            pred = nd.from_numpy(decode_multiple_block(out_1, out_2)).astype(\"float32\").as_in_context(mx.cpu())\n",
    "            IoU = BatchIoU(pred,gt)\n",
    "            print(\"Train: epoch {} batch {}/{},loss_cls = {:.3f},loss_reg = {:.3f},acc = {:.3f},IoU = {:.3f},time = {:.2f}\"\n",
    "                  .format(epoch, idx, len(train_loader), loss_cls, loss_reg, acc[0].asscalar(), IoU.mean(),end - start))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "\n",
    "def validate(epoch, val_loader, model, crit_cls, crit_reg, opt,ctx, gen_shape=False):\n",
    "    \"\"\"\n",
    "    One validation\n",
    "    \"\"\"\n",
    "    generated_shapes = []\n",
    "    original_shapes = []\n",
    "    sample_prob = opt.inner_sample_prob\n",
    "    loss_cls_sum,loss_reg_sum,n = 0.0,0.0,0\n",
    "    \n",
    "    for idx, data in enumerate(val_loader):\n",
    "        start = time.time()\n",
    "\n",
    "        shapes, labels, masks, params, param_masks = data[0], data[1], data[2], data[3], data[4]\n",
    "        gt = shapes\n",
    "        shapes = nd.expand_dims(shapes, axis = 1)\n",
    "\n",
    "        shapes = shapes.as_in_context(ctx)\n",
    "        labels = labels.as_in_context(ctx)\n",
    "        masks = masks.as_in_context(ctx)\n",
    "        params = params.as_in_context(ctx)\n",
    "        param_masks = param_masks.as_in_context(ctx)\n",
    "        #with autograd.train_mode():\n",
    "        out = model.decode(shapes)\n",
    "        #out = model(shapes, labels, sample_prob)\n",
    "        bsz, n_block, n_step = labels.shape\n",
    "        labels = labels.reshape(bsz, n_block * n_step)\n",
    "        masks = masks.reshape(bsz, n_block * n_step)\n",
    "        out_pgm = out[0].reshape(bsz, n_block * n_step, opt.program_size + 1)\n",
    "\n",
    "        bsz, n_block, n_step, n_param = params.shape\n",
    "        params = params.reshape(bsz, n_block * n_step, n_param)\n",
    "        param_masks = param_masks.reshape(bsz, n_block * n_step, n_param)\n",
    "        out_param = out[1].reshape(bsz, n_block * n_step, n_param)\n",
    "        loss_cls, acc = crit_cls(out_pgm, labels, masks)\n",
    "        loss_reg = crit_reg(out_param, params, param_masks)\n",
    "   \n",
    "        end = time.time()\n",
    "        \n",
    "        \n",
    "        loss_cls = loss_cls.mean().asscalar()\n",
    "        loss_reg = loss_reg.mean().asscalar()\n",
    "        \n",
    "        \n",
    "        if idx % opt.info_interval == 0:\n",
    "            out_1 = nd.round(out[0]).astype('int64')\n",
    "            out_2 = nd.round(out[1]).astype('int64')\n",
    "            pred = nd.from_numpy(decode_multiple_block(out_1, out_2)).astype(\"float32\").as_in_context(mx.cpu())\n",
    "            IoU = BatchIoU(pred,gt)\n",
    "            print(\"Test: epoch {} batch {}/{}, loss_cls = {:.3f}, loss_reg = {:.3f}, acc = {:.3f}, IoU = {:.3f} time = {:.3f}\"\n",
    "                  .format(epoch, idx, len(val_loader), loss_cls, loss_reg, acc[0].asscalar(), IoU.mean(), end - start))\n",
    "            sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== arguments: program generator =====\n",
      "learning_rate        0.001\n",
      "weight_decay         0\n",
      "beta1                0.9\n",
      "beta2                0.999\n",
      "grad_clip            0.1\n",
      "epochs               20\n",
      "info_interval        5\n",
      "save_interval        5\n",
      "program_size         21\n",
      "max_param            7\n",
      "shape_feat_size      64\n",
      "outer_input_size     64\n",
      "outer_rnn_size       64\n",
      "outer_num_layers     1\n",
      "outer_drop_prob      0\n",
      "outer_seq_length     10\n",
      "inner_input_size     64\n",
      "inner_rnn_size       64\n",
      "inner_num_layers     1\n",
      "inner_drop_prob      0\n",
      "inner_seq_length     3\n",
      "inner_cls_feat_size  64\n",
      "inner_reg_feat_size  64\n",
      "inner_sample_prob    1.1\n",
      "cls_weight           1\n",
      "reg_weight           3\n",
      "train_file           ./data/train_shapes.h5\n",
      "val_file             ./data/val_shapes.h5\n",
      "batch_size           32\n",
      "num_workers          4\n",
      "model_name           program_generator\n",
      "save_folder          ./model/ckpts_program_generator\n",
      "===== arguments: program generator =====\n"
     ]
    }
   ],
   "source": [
    "opt = options_train_generator.parse()\n",
    "\n",
    "print('===== arguments: program generator =====')\n",
    "for key, val in vars(opt).items():\n",
    "    print(\"{:20} {}\".format(key, val))\n",
    "print('===== arguments: program generator =====')\n",
    "\n",
    "if not os.path.isdir(opt.save_folder):\n",
    "    os.makedirs(opt.save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "ctx = d2l.try_gpu()\n",
    "model = BlockOuterNet(opt)\n",
    "model.init_blocks(ctx)\n",
    "\n",
    "crit_cls = LSTMClassCriterion()\n",
    "crit_reg = LSTMRegressCriterion()\n",
    "ctri_cls = crit_cls.initialize(ctx = ctx)\n",
    "ctri_reg = crit_reg.initialize(ctx = ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = Trainer(model.collect_params(),\"adam\",\n",
    "                    {\"learning_rate\":opt.learning_rate,\"wd\":opt.weight_decay,\n",
    "                     'beta1':opt.beta1, 'beta2':opt.beta2, 'clip_gradient': opt.grad_clip})\n",
    "train_from0 = False;\n",
    "if train_from0:\n",
    "    if os.path.exists(\"model/model of blockouternet2\"):\n",
    "        model.load_parameters('model/model of blockouternet2')\n",
    "        print(\"loaded parameter of model2\")\n",
    "    if os.path.exists('model/optimizer of PG2'):\n",
    "        optimizer.load_states('model/optimizer of PG2')\n",
    "        print(\"loaded state of trainer2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      "training\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"src/api/operator/numpy/../../../imperative/imperative_utils.h\", line 370\nMXNetError: Check failed: num_inputs == infered_num_inputs (1 vs. 5) : Operator BatchNorm expects 5 inputs, but got 1 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-571629e7c3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"###################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7ad284a74abc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, train_loader, model, crit_cls, crit_reg, optimizer, opt, ctx)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#shapes.attach_grad(),labels.attach_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m#out = model.decode(shapes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/shape2prog-master/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, sample_prob)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#print(combine(x,rendered_shapes).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mfc_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrendered_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/shape2prog-master/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmoving_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;31m#x = self.block(x);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mBatchNorm\u001b[0;34m(data, gamma, beta, moving_mean, moving_var, eps, momentum, fix_gamma, use_global_stats, output_mean_var, axis, cudnn_off, min_calib_range, max_calib_range, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out, is_np_op, output_is_list)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mcreate_ndarray_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_global_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_np_ndarray_cls\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_np_op\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_global_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"src/api/operator/numpy/../../../imperative/imperative_utils.h\", line 370\nMXNetError: Check failed: num_inputs == infered_num_inputs (1 vs. 5) : Operator BatchNorm expects 5 inputs, but got 1 instead."
     ]
    }
   ],
   "source": [
    "\n",
    "L2_loss = gloss.L2Loss()\n",
    "#optimizer = Trainer(model.collect_params(),\"sgd\",\n",
    "#                    {\"learning_rate\":opt.learning_rate,\"wd\":opt.weight_decay,'clip_gradient': opt.grad_clip})\n",
    "\n",
    "# build dataloader\n",
    "\n",
    "train_set = Synthesis3D(opt.train_file, n_block=opt.outer_seq_length)\n",
    "train_loader = gdata.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.num_workers,\n",
    ")\n",
    "val_set = Synthesis3D(opt.val_file, n_block=opt.outer_seq_length)\n",
    "val_loader = gdata.DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.num_workers,\n",
    ")\n",
    "\n",
    "for epoch in range(1, opt.epochs+1):\n",
    "    print(\"###################\")\n",
    "    print(\"training\")\n",
    "    \n",
    "    train(epoch, train_loader, model, crit_cls, crit_reg, optimizer, opt,ctx)\n",
    "\n",
    "    print(\"###################\")\n",
    "    print(\"testing\")\n",
    "    validate(epoch, val_loader, model, crit_cls, crit_reg, opt,ctx,True)\n",
    "    if epoch % 1 == 0:\n",
    "        print('Saving...')\n",
    "        optimizer.save_states('model/optimizer of PG2'),\n",
    "        model.save_parameters(\"model/model of blockouternet2\")\n",
    "        #state = {\n",
    "        #    'opt': opt,\n",
    "        #    'epoch': epoch\n",
    "        #}\n",
    "        #save_file = os.path.join(opt.save_folder, 'ckpt_epoch_{epoch}.t7'.format(epoch=epoch))\n",
    "        #np.save(state, save_file)\n",
    "optimizer.save_states('model/optimizer of PG2'),\n",
    "model.save_parameters(\"model/model of blockouternet2\")\n",
    "#state = {\n",
    "#    'opt': opt,\n",
    "#    'epoch': opt.epochs\n",
    "#}\n",
    "#save_file = os.path.join(opt.save_folder, 'program_generator.t7')\n",
    "#nd.save(state, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "def set_bn_eval(m):\n",
    "    if m.prefix[:9]=='batchnorm':\n",
    "        m._kwargs['momentum'] = 0       \n",
    "model.apply(set_bn_eval)\n",
    "'''\n",
    "for epoch in range(1, opt.epochs+1):\n",
    "    print(\"###################\")\n",
    "    print(\"testing\")\n",
    "    validate(epoch, val_loader, model, crit_cls, crit_reg, opt,ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer.set_learning_rate(opt.learning_rate*0.1)\n",
    "optimizer.save_states('model/optimizer of PG2'),\n",
    "model.save_parameters(\"model/model of blockouternet2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nd.arange(10).astype('int32')\n",
    "b = nd.random_randint(10,13,shape = a.shape)\n",
    "idx = nd.random_randint(0,2,shape = a.shape)\n",
    "print(idx,a,b)\n",
    "nd.where(idx,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

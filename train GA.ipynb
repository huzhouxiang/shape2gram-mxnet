{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd,autograd,init\n",
    "from mxnet.gluon import Trainer,data as gdata,loss as gloss,nn\n",
    "from d2l import mxnet as d2l\n",
    "\n",
    "from dataset import ShapeNet3D\n",
    "from model import BlockOuterNet, RenderNet\n",
    "from criterion import BatchIoU\n",
    "from misc import clip_gradient, decode_multiple_block\n",
    "from options import options_guided_adaptation,options_train_generator,options_train_executor\n",
    "from visualization.util_vtk import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, generator, executor, criterion, optimizer, opt,ctx):\n",
    "    \"\"\"\n",
    "    one epoch guided adaptation\n",
    "    \"\"\"\n",
    "\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        shapes = data.as_in_context(ctx)\n",
    "        raw_shapes = data\n",
    "        shapes = shapes.expand_dims(axis = 1)\n",
    "        with autograd.record():\n",
    "            pgms, params = generator.decode(shapes)\n",
    "            \n",
    "            # truly rendered shapes\n",
    "            pgms_int = nd.round(pgms).astype('int64')\n",
    "            params_int = nd.round(params).astype('int64')\n",
    "           \n",
    "\n",
    "            # neurally rendered shapes\n",
    "            pgms = nd.exp(pgms)\n",
    "            bsz, n_block, n_step, n_vocab = pgms.shape\n",
    "            pgm_vector = pgms.reshape(bsz*n_block, n_step, n_vocab)\n",
    "            bsz, n_block, n_step, n_param = params.shape\n",
    "            param_vector = params.reshape(bsz*n_block, n_step, n_param)\n",
    "            index = (n_step - 1) * nd.ones(bsz * n_block).astype('int64')\n",
    "            index = index.as_in_context(ctx)\n",
    "            pred = executor(pgm_vector, param_vector, index)\n",
    "            pred = nd.softmax(pred,axis = 1)\n",
    "            #print(pred.shape)\n",
    "            pred = pred[:, 1]\n",
    "            pred = pred.reshape(bsz, n_block, 32, 32, 32)\n",
    "            \n",
    "            rec = nd.max(pred, axis=1)\n",
    "            rec1 = nd.log(rec+ 1e-11)\n",
    "            rec0 = nd.log(1 - rec+1e-11)\n",
    "            gt = shapes.squeeze().astype('int64')\n",
    "            loss = -nd.where(gt,rec1,rec0).mean(axis = (1,2,3))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step(loss.shape[0],ignore_stale_grad=True)\n",
    "        l = loss.mean().asscalar()\n",
    "        \n",
    "        rendered_shapes = decode_multiple_block(pgms_int, params_int)\n",
    "        rendered_shapes = nd.from_numpy(rendered_shapes).astype('float32').as_in_context(mx.cpu())\n",
    "        IoU2= BatchIoU(raw_shapes,rendered_shapes)\n",
    "        reconstruction = (rec.as_in_context(mx.cpu())>0.5).astype('float32')\n",
    "        IoU1 = BatchIoU(reconstruction, raw_shapes)\n",
    "        #print(\"IoU1:\",IoU1,IoU2)\n",
    "        IoU1 = IoU1.mean()\n",
    "        IoU2 = IoU2.mean()\n",
    "        \n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        if idx % opt.info_interval == 0:\n",
    "            print(\"Train: epoch {} batch {}/{}, loss = {:.3f}, IoU1 = {:.3f}, IoU2 = {:.3f}, time = {:.3f}\"\n",
    "                  .format(epoch, idx, len(train_loader), l, IoU1, IoU2, end - start))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "\n",
    "def validate(epoch, val_loader, generator, opt,ctx,gen_shape=False):\n",
    "    \"\"\"\n",
    "    evaluate program generator, in terms of IoU\n",
    "    \"\"\"\n",
    "    generated_shapes = []\n",
    "    original_shapes = []\n",
    "    for idx, data in enumerate(val_loader):\n",
    "        start = time.time()\n",
    "        shapes = data.as_in_context(ctx)\n",
    "        shapes = nd.expand_dims(shapes, axis=1)\n",
    "        with autograd.train_mode():\n",
    "            out = generator.decode(shapes)\n",
    "\n",
    "        end = time.time()\n",
    "        \n",
    "        if gen_shape:\n",
    "            out_1 = nd.round(out[0]).astype('int64')\n",
    "            out_2 = nd.round(out[1]).astype('int64')\n",
    "            generated_shapes.append(decode_multiple_block(out_1, out_2).astype(\"float32\"))\n",
    "            original_shapes.append(data.asnumpy())\n",
    "\n",
    "        if idx % opt.info_interval == 0:\n",
    "            print(\"Test: epoch {} batch {}/{}, time={:.3f}\"\n",
    "                  .format(epoch, idx, len(val_loader), end - start))\n",
    "\n",
    "    if gen_shape:\n",
    "        generated_shapes = np.concatenate(generated_shapes, axis=0)\n",
    "        original_shapes = np.concatenate(original_shapes, axis=0)\n",
    "\n",
    "    return generated_shapes, original_shapes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== arguments: guided adaptation =====\n",
      "learning_rate        2e-05\n",
      "weight_decay         1e-05\n",
      "beta1                0.9\n",
      "beta2                0.999\n",
      "epochs               10\n",
      "grad_clip            0.1\n",
      "info_interval        10\n",
      "save_interval        5\n",
      "batch_size           32\n",
      "num_workers          4\n",
      "data_folder          ./data/\n",
      "cls                  chair\n",
      "p_gen_path           ./model/ckpts_program_generator/program_generator.t7\n",
      "p_exe_path           ./model/ckpts_program_executor/program_executor.t7\n",
      "model_name           GA\n",
      "save_folder          ./model/ckpts_GA_chair\n",
      "train_file           ./data/chair_training.h5\n",
      "val_file             ./data/chair_testing.h5\n",
      "===== arguments: guided adaptation =====\n"
     ]
    }
   ],
   "source": [
    "# get options\n",
    "opt = options_guided_adaptation.parse()\n",
    "opt_gen = options_train_generator.parse()\n",
    "opt_exe = options_train_executor.parse()\n",
    "print('===== arguments: guided adaptation =====')\n",
    "for key, val in vars(opt).items():\n",
    "    print(\"{:20} {}\".format(key, val))\n",
    "print('===== arguments: guided adaptation =====')\n",
    "\n",
    "if not os.path.isdir(opt.save_folder):\n",
    "    os.makedirs(opt.save_folder)\n",
    "\n",
    "# build loaders\n",
    "train_set = ShapeNet3D(opt.train_file)\n",
    "train_loader = gdata.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.num_workers\n",
    ")\n",
    "\n",
    "val_set = ShapeNet3D(opt.val_file)\n",
    "val_loader = gdata.DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=opt.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual(path,epoch,gen_shapes,file_name,nums_samples):\n",
    "    data = gen_shapes.transpose((0, 3, 2, 1))\n",
    "    data = np.flip(data, axis=2)\n",
    "    num_shapes = data.shape[0]\n",
    "    for i in range(min(nums_samples,num_shapes)):\n",
    "        voxels = data[i]\n",
    "        save_name = os.path.join(path, file_name.format(epoch,i))\n",
    "        visualization(voxels,\n",
    "                      threshold=0.1,\n",
    "                      save_name=save_name,\n",
    "                      uniform_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = d2l.try_gpu()\n",
    "\n",
    "# load program generator\n",
    "generator = BlockOuterNet(opt_gen)\n",
    "generator.init_blocks(ctx)\n",
    "generator.load_parameters(\"model/model of blockouternet\")\n",
    "\n",
    "\n",
    "# load program executor\n",
    "executor = RenderNet(opt_exe)\n",
    "executor.initialize(init = init.Xavier(),ctx = ctx)\n",
    "executor.load_parameters(\"model/model of executor\")\n",
    "\n",
    "def set_bn_eval(m):\n",
    "    if m.prefix[:9]=='batchnorm':\n",
    "        m._kwargs['use_global_stats']=True      \n",
    "executor.apply(set_bn_eval)\n",
    "\n",
    "\n",
    "# build loss functions\n",
    "criterion = gloss.SoftmaxCrossEntropyLoss(axis=1,from_logits=True)\n",
    "\n",
    "optimizer = Trainer(generator.collect_params(),\"adam\",\n",
    "                    {\"learning_rate\":opt.learning_rate,\"wd\":opt.weight_decay,\n",
    "                     'beta1':opt.beta1, 'beta2':opt.beta2,'clip_gradient': opt.grad_clip})\n",
    "\n",
    "'''\n",
    "optimizer = Trainer(generator.collect_params(),\"sgd\",\n",
    "                {\"learning_rate\":opt.learning_rate*30,\"momentum\":0.1,\n",
    "                 \"wd\":opt.weight_decay,'clip_gradient': opt.grad_clip})\n",
    "'''\n",
    "print(\"###################\")\n",
    "print(\"testing\")\n",
    "gen_shapes, ori_shapes = validate(0, val_loader, generator, opt,ctx,gen_shape=True)\n",
    "if os.path.exists('imgs of chairs/adaption/{}/'.format(opt.cls)) == False:\n",
    "    os.mkdir('imgs of chairs/adaption/{}/'.format(opt.cls));\n",
    "#visual('imgs of chairs/adaption/{}/'.format(opt.cls),0,ori_shapes,'GT {}-{}.png',8)\n",
    "#visual('imgs of chairs/adaption/{}/'.format(opt.cls),0,gen_shapes,'epoch{}-{}.png',8)\n",
    "\n",
    "gen_shapes = nd.from_numpy(gen_shapes)\n",
    "ori_shapes = nd.from_numpy(ori_shapes)\n",
    "#print(gen_shapes.dtype,ori_shapes.dtype)\n",
    "#print(\"done\",ori_shapes.shape,gen_shapes.shape)\n",
    "\n",
    "\n",
    "IoU = BatchIoU(gen_shapes,ori_shapes)\n",
    "#print(IoU)\n",
    "print(\"iou: \", IoU.mean())\n",
    "\n",
    "\n",
    "best_iou ,best_epoch= 0,0\n",
    "print(opt.epochs)\n",
    "for epoch in range(1, opt.epochs+1):\n",
    "    print(\"###################\")\n",
    "    print(\"adaptation\")\n",
    "    train(epoch, train_loader, generator, executor, criterion, optimizer, opt,ctx)\n",
    "    print(\"###################\")\n",
    "    print(\"testing\")\n",
    "    gen_shapes, ori_shapes = validate(epoch, val_loader, generator, opt,ctx,gen_shape=True)\n",
    "    #visual('imgs of chairs/adaption/{}/'.format(opt.cls),epoch,gen_shapes,'epoch{}-{}.png',8)\n",
    "    gen_shapes = nd.from_numpy(gen_shapes)\n",
    "    ori_shapes = nd.from_numpy(ori_shapes)\n",
    "    IoU = BatchIoU(gen_shapes,ori_shapes)\n",
    "    print(\"iou: \", IoU.mean())\n",
    "    \n",
    "\n",
    "    if IoU.mean() >= best_iou:\n",
    "        print('Saving best model')\n",
    "        generator.save_parameters(\"model/generator of GA on shapenet \"+opt.cls)\n",
    "        best_iou = IoU.mean()\n",
    "        best_epoch = epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_iou,best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
